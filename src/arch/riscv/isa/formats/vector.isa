// SPDX-FileCopyrightText: Copyright Â© 2022 by Rivos Inc.
// Licensed under the Apache License, Version 2.0, see LICENSE for details.
// SPDX-License-Identifier: Apache-2.0

// Copyright (c) 2022 The Regents of the University of California
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are
// met: redistributions of source code must retain the above copyright
// notice, this list of conditions and the following disclaimer;
// redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution;
// neither the name of the copyright holders nor the names of its
// contributors may be used to endorse or promote products derived from
// this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

// --- Start of VectorCfg

def template VectorCfgConstructor {{
    %(class_name)s::%(class_name)s(MachInst machInst, RiscvISA::VTYPE machVtype, uint32_t machVl, int vlen)
        : %(base_class)s("%(mnemonic)s", machInst, VectorCfgOpClass, machVtype, machVl, vlen)
    {
        %(set_reg_idx_arr)s;
        %(constructor)s;
        flags[IsVector] = true;
    }
}};

def template VectorConfigExecute {{
    Fault
    %(class_name)s::execute(ExecContext *xc,
        Trace::InstRecord *traceData) const
    {
        Fault fault = NoFault;

        RiscvISA::VTYPE new_vtype = 0xFFFFFFFF; // will have an illegal [30:8]

        %(op_decl)s;
        %(op_rd)s;

        if (fault == NoFault) {

            %(code)s;

            if (fault == NoFault) {
                %(op_wb)s;
            }
        }

        //NPC = NPC;
        RiscvISA::PCState newPCState;
        set(newPCState, xc->pcState());
        newPCState.vtype(new_vtype);
        newPCState.vl(Rd); // the new vl is returned in Rd
        xc->pcState(newPCState);

        xc->tcBase()->pcState(newPCState);

        return fault;
    }
}};

def format VectorCfgOp(execute_code, branch_target_code, *opt_flags) {{
    iop = InstObjParams(name, Name, 'VectorCfgOp', {'code': execute_code}, opt_flags)
    header_output = VectorCfgDeclare.subst(iop)
    decoder_output = VectorCfgConstructor.subst(iop)
    decode_block = VectorDecode.subst(iop)
    exec_output = VectorConfigExecute.subst(iop)
}};

// --- End of VectorCfg

// --- Start of OPIVI

def template VectorOPIVIMacroOpConstructor {{
    %(class_name)s::%(class_name)s(MachInst machInst, RiscvISA::VTYPE machVtype, uint32_t machVl, int vlen)
        : %(base_class)s("%(mnemonic)s", machInst, VectorOPIVIMacroClass, machVtype, machVl, vlen)
    {
        // Example:
        // vadd.vi        31..26=0x00 vm vs2 simm5 14..12=0x3 vd 6..0=0x57

        //_numVecSrcRegs = _numTypedDestRegs[VecRegClass] =
        //    ceil((float) machVl / (VecRegSizeBytes / sewb));
        //assert((VD % alignToPowerOfTwo(_numTypedDestRegs[VecRegClass])) == 0);
        //assert((VS2 % alignToPowerOfTwo(_numTypedDestRegs[VecRegClass])) == 0);

        auto sew = getSew(machVtype.vsew);
        uint32_t num_elements_per_reg = vlen / sew;
        uint32_t element_count = machVl;

        auto num_vregs = vlmulToNumRegs(machVtype.vlmul);

        for (uint32_t reg_id_offset = 0; reg_id_offset < num_vregs; reg_id_offset++)
        {
            StaticInstPtr uop = new %(class_name)sMicro(machInst, machVtype, machVl,
                VD+reg_id_offset, VS2+reg_id_offset, VM, reg_id_offset*num_elements_per_reg, num_elements_per_reg,
                (element_count < num_elements_per_reg) ? element_count : num_elements_per_reg,
                sew, (uint64_t)machVtype.vma, (uint64_t)machVtype.vta);
            element_count = (element_count >= num_elements_per_reg) ? (element_count - num_elements_per_reg) : 0;
            microops.push_back(std::move(uop));
        }

        microops.front()->setFlag(IsFirstMicroop);
        microops.back()->setFlag(IsLastMicroop);

        flags[IsVector] = true;
    }
}};

def template VectorOPIVIMicroOpConstructor {{
    %(class_name)s::%(class_name)sMicro::%(class_name)sMicro(MachInst machInst,
        RiscvISA::VTYPE machVtype, uint32_t machVl,
        uint64_t vdRegID, uint64_t vs2RegID,
        uint64_t vmRegID, uint64_t mask_offset,
        uint64_t num_elements_per_reg, uint64_t num_non_tail_elements,
        uint64_t sew, uint64_t mask_policy, uint64_t tail_policy)
        : %(base_class)s("%(mnemonic)s", machInst, VectorOPIVIMicroClass,
            vdRegID, vs2RegID, vmRegID, mask_offset,
            num_elements_per_reg, num_non_tail_elements,
            sew, mask_policy, tail_policy)
    {
        %(set_reg_idx_arr)s;

        // Example:
        // vadd.vv         31..26=0x00 vm vs2 vs1 14..12=0x0 vd 6..0=0x57
        // vreg[vdRegID] = vreg[vs1RegID] + vreg[vs2RegID]

        // Set register dependencies
        //setDestRegIdx(_numDestRegs++, RegId(VecRegClass, vdRegID));
        setDestRegIdx(_numDestRegs++, vecRegClass[vdRegID]);
        //setSrcRegIdx(_numSrcRegs++, RegId(VecRegClass, vs2RegID));
        setSrcRegIdx(_numSrcRegs++, vecRegClass[vs2RegID]);

        if (vmRegID == 0) { // The mask register is always v0
            // Masked instruction.
            //setSrcRegIdx(_numSrcRegs++, RegId(VecRegClass, 0));
            setSrcRegIdx(_numSrcRegs++, vecRegClass[0]);
        }

        //if (tail_policy == 0) // undisturbed
        if (num_non_tail_elements < num_elements_per_reg)
            //setSrcRegIdx(_numSrcRegs++, RegId(VecRegClass, vdRegID));
            setSrcRegIdx(_numSrcRegs++, vecRegClass[vdRegID]);

        _numVecSrcRegs = _numSrcRegs;

        flags[IsInteger] = true;
        flags[IsVector] = true;
        flags[IsMicroop] = true;
    }
}};

def template VectorOPIVIMicroExecute {{
    Fault
    %(class_name)s::%(class_name)sMicro::execute(ExecContext *xc,
        Trace::InstRecord *traceData) const
    {
        Fault fault = NoFault;

        //uint32_t vl = xc->readMiscReg(MISCREG_VL);
        //VTYPE vtype = xc->readMiscReg(MISCREG_VTYPE);
        //size_t sewb = getSew(vtype.vsew) / 8;

        if (VM == 0) {
             if (VD == 0 || VS2 == 0) {
                std::string error =
                    csprintf("Masked VectorOPIVI using v0 "
                             "as src/dst register\n");
                return std::make_shared<IllegalInstFault>(error, machInst);
             }
        }

        bool has_to_copy_tail_elements = num_non_tail_elements < num_elements_per_reg;

        auto empty_vmask = std::vector<uint8_t>((num_non_tail_elements + 7)/8, 0xFF);
        uint8_t* vmask = empty_vmask.data();
        // Figure out if we need masks
        if (vmRegID == 0) {
            RiscvISA::VecRegContainer Vmask_container;
            xc->getRegOperand(this, 2, &Vmask_container);
            vmask = Vmask_container.as<uint8_t>();
        }

        uint32_t tail_reg_idx = (vmRegID == 0) ? 2 : 1;
        RiscvISA::VecRegContainer old_Vd_container;
        if (has_to_copy_tail_elements)
            xc->getRegOperand(this, tail_reg_idx, &old_Vd_container);        

        bool utilize_mask = vmRegID == 0;

        auto &Vd_container = *(RiscvISA::VecRegContainer *)xc->getWritableRegOperand(this, 0);
        RiscvISA::VecRegContainer Vs2_container;
        xc->getRegOperand(this, 0, &Vs2_container);

        if (fault == NoFault) {
            if (sew == 8) {
                auto Vd = Vd_container.as<uint8_t>();
                auto Vs2 = Vs2_container.as<uint8_t>();
                for (size_t regElemID = 0; regElemID < num_elements_per_reg; ++regElemID) {
                    uint32_t maskElemID = mask_offset + regElemID;
                    if (utilize_mask && (bits(vmask[maskElemID / 8], maskElemID % 8, maskElemID % 8) == 0)) {  // "mask undisturbed" policy
                        continue;
                    }
                    %(code)s;
                }
                if (has_to_copy_tail_elements)
                {
                    auto old_Vd = old_Vd_container.as<uint8_t>();
                    for (uint32_t regElemID = num_non_tail_elements; regElemID < num_elements_per_reg; ++regElemID) {
                        Vd[regElemID] = old_Vd[regElemID];
                    }
                }
            } else if (sew == 16) {
                auto Vd = Vd_container.as<uint16_t>();
                auto Vs2 = Vs2_container.as<uint16_t>();
                for (size_t regElemID = 0; regElemID < num_elements_per_reg; ++regElemID) {
                    uint32_t maskElemID = mask_offset + regElemID;
                    if (utilize_mask && (bits(vmask[maskElemID / 8], maskElemID % 8, maskElemID % 8) == 0)) {  // "mask undisturbed" policy
                        continue;
                    }
                    %(code)s;
                }
                if (has_to_copy_tail_elements)
                {
                    auto old_Vd = old_Vd_container.as<uint16_t>();
                    for (uint32_t regElemID = num_non_tail_elements; regElemID < num_elements_per_reg; ++regElemID) {
                        Vd[regElemID] = old_Vd[regElemID];
                    }
                }
            } else if (sew == 32) {
                auto Vd = Vd_container.as<uint32_t>();
                auto Vs2 = Vs2_container.as<uint32_t>();
                for (size_t regElemID = 0; regElemID < num_elements_per_reg; ++regElemID) {
                    uint32_t maskElemID = mask_offset + regElemID;
                    if (utilize_mask && (bits(vmask[maskElemID / 8], maskElemID % 8, maskElemID % 8) == 0)) {  // "mask undisturbed" policy
                        continue;
                    }
                    %(code)s;
                }
                if (has_to_copy_tail_elements)
                {
                    auto old_Vd = old_Vd_container.as<uint32_t>();
                    for (uint32_t regElemID = num_non_tail_elements; regElemID < num_elements_per_reg; ++regElemID) {
                        Vd[regElemID] = old_Vd[regElemID];
                    }
                }
            } else if (sew == 64) {
                auto Vd = Vd_container.as<uint64_t>();
                auto Vs2 = Vs2_container.as<uint64_t>();
                for (size_t regElemID = 0; regElemID < num_elements_per_reg; ++regElemID) {
                    uint32_t maskElemID = mask_offset + regElemID;
                    if (utilize_mask && (bits(vmask[maskElemID / 8], maskElemID % 8, maskElemID % 8) == 0)) {  // "mask undisturbed" policy
                        continue;
                    }
                    %(code)s;
                }
                if (has_to_copy_tail_elements)
                {
                    auto old_Vd = old_Vd_container.as<uint64_t>();
                    for (uint32_t regElemID = num_non_tail_elements; regElemID < num_elements_per_reg; ++regElemID) {
                        Vd[regElemID] = old_Vd[regElemID];
                    }
                }
            } else {
                std::string error = csprintf(
                    "Illegal vsewb value in VTYPE: 0x%x\n", sew);
                fault = std::make_shared<IllegalInstFault>(error, machInst);
            }
            if (fault == NoFault) {
                if (traceData) {
                    traceData->setData(vecRegClass, &Vd_container);
                }
            }
        }

        return fault;
    }
}};

def template VectorOPIVIMicroDeclare {{
    //
    // Static instruction class for "%(mnemonic)s".
    //
    class %(class_name)s::%(class_name)sMicro : public %(base_class)s
    {
      private:
        // Example:
        // vadd.vi        31..26=0x00 vm vs2 simm5 14..12=0x3 vd 6..0=0x57
        // Sources: up to 1 vector regs starting at Vs2 and
        //          1 mask register and
        //          1 destination register.
        RegId srcRegIdxArr[1 + 1 + 1];
        // Destinations: up to 8 vector regs starting at Vd
        RegId destRegIdxArr[1];

      public:
        /// Constructor.
        %(class_name)sMicro(MachInst machInst,
        RiscvISA::VTYPE machVtype, uint32_t machVl,
        uint64_t vdRegID, uint64_t vs2RegID,
        uint64_t vmRegID, uint64_t mask_offset,
        uint64_t num_elements_per_reg, uint64_t num_non_tail_elements,
        uint64_t sew, uint64_t mask_policy, uint64_t tail_policy);
        Fault execute(ExecContext *, Trace::InstRecord *) const override;
        using %(base_class)s::generateDisassembly;
    };
}};

def format VectorOPIVIMacroOp(code, *opt_flags) {{
    macro_iop = InstObjParams(name, Name, 'VectorOPIVIMacroOp', code, opt_flags)
    header_output = VectorMacroDeclare.subst(macro_iop)
    decoder_output = VectorOPIVIMacroOpConstructor.subst(macro_iop)
    decode_block = VectorMacroDecode.subst(macro_iop)
    exec_output = VectorMacroExecute.subst(macro_iop)


    uop_iop = InstObjParams(name, Name, 'VectorOPIVIMicroOp', code, opt_flags)
    header_output += VectorOPIVIMicroDeclare.subst(uop_iop)
    decoder_output += VectorOPIVIMicroOpConstructor.subst(uop_iop)
    decode_block += VectorMicroDecode.subst(uop_iop)
    exec_output += VectorOPIVIMicroExecute.subst(uop_iop)
}};

// --- End of OPIVI

// --- Start of VectorVdVs2Vs1

def template VectorVdVs2Vs1MacroOpConstructor {{
    %(class_name)s::%(class_name)s(MachInst machInst, RiscvISA::VTYPE machVtype, uint32_t machVl, int vlen)
        : %(base_class)s("%(mnemonic)s", machInst, VectorVdVs2Vs1MacroOpClass, machVtype, machVl, vlen)
    {
        // Example:
        // vadd.vv         31..26=0x00 vm vs2 vs1 14..12=0x0 vd 6..0=0x57

        //_numTypedDestRegs[VecRegClass] =
        //    ceil((float) machVl / (VecRegSizeBytes / sewb));
        //assert((VD % alignToPowerOfTwo(_numTypedDestRegs[VecRegClass])) == 0);
        //assert((VS1 % alignToPowerOfTwo(_numTypedDestRegs[VecRegClass])) == 0);
        //assert((VS2 % alignToPowerOfTwo(_numTypedDestRegs[VecRegClass])) == 0);

        auto sew = getSew(machVtype.vsew);
        uint32_t num_elements_per_reg = vlen / sew;
        uint32_t element_count = machVl;

        auto num_vregs = vlmulToNumRegs(machVtype.vlmul);
        microops = std::vector<StaticInstPtr>();

        for (uint32_t reg_id_offset = 0; reg_id_offset < num_vregs; reg_id_offset++)
        {
            StaticInstPtr uop = new %(class_name)sMicro(machInst, machVtype, machVl,
                VD+reg_id_offset, VS1+reg_id_offset, VS2+reg_id_offset,
                VM, reg_id_offset*num_elements_per_reg, num_elements_per_reg,
                (element_count < num_elements_per_reg) ? element_count : num_elements_per_reg,
                sew, (uint64_t)machVtype.vma, (uint64_t)machVtype.vta);
            element_count = (element_count >= num_elements_per_reg) ? (element_count - num_elements_per_reg) : 0;
            microops.push_back(std::move(uop));
        }

        microops.front()->setFlag(IsFirstMicroop);
        microops.back()->setFlag(IsLastMicroop);

        flags[IsVector] = true;
    }
}};

def template VectorVdVs2Vs1MicroConstructor {{
    %(class_name)s::%(class_name)sMicro::%(class_name)sMicro(MachInst machInst,
        RiscvISA::VTYPE machVtype, uint32_t machVl,
        uint64_t vdRegID, uint64_t vs1RegID, uint64_t vs2RegID,
        uint64_t vmRegID, uint64_t mask_offset,
        uint64_t num_elements_per_reg, uint64_t num_non_tail_elements,
        uint64_t sew, uint64_t mask_policy, uint64_t tail_policy)
        : %(base_class)s("%(mnemonic)s", machInst, VectorVdVs2Vs1MicroOpClass,
            vdRegID, vs1RegID, vs2RegID, vmRegID, mask_offset,
            num_elements_per_reg, num_non_tail_elements,
            sew, mask_policy, tail_policy)
    {
        %(set_reg_idx_arr)s;

        // Example:
        // vadd.vv         31..26=0x00 vm vs2 vs1 14..12=0x0 vd 6..0=0x57
        // vreg[vdRegID] = vreg[vs1RegID] + vreg[vs2RegID]

        // Set register dependencies
        //setDestRegIdx(_numDestRegs++, RegId(VecRegClass, vdRegID));
        setDestRegIdx(_numDestRegs++, vecRegClass[vdRegID]);
        //setSrcRegIdx(_numSrcRegs++, RegId(VecRegClass, vs1RegID));
        setSrcRegIdx(_numSrcRegs++, vecRegClass[vs1RegID]);
        //setSrcRegIdx(_numSrcRegs++, RegId(VecRegClass, vs2RegID));
        setSrcRegIdx(_numSrcRegs++, vecRegClass[vs2RegID]);
        if (vmRegID == 0) { // The mask register is always v0
            // Masked instruction.
            //setSrcRegIdx(_numSrcRegs++, RegId(VecRegClass, 0));
            setSrcRegIdx(_numSrcRegs++, vecRegClass[0]);
        }
        //if (tail_policy == 0) // undisturbed
        if (num_non_tail_elements < num_elements_per_reg)
        {
            //setSrcRegIdx(_numSrcRegs++, RegId(VecRegClass, vdRegID));
            setSrcRegIdx(_numSrcRegs++, vecRegClass[vdRegID]);
        }

        _numVecSrcRegs = _numSrcRegs;

        flags[IsInteger] = true;
        flags[IsVector] = true;
        flags[IsMicroop] = true;
    }
}};

def template VectorVdVs2Vs1OpMicroExecute {{
    Fault
    %(class_name)s::%(class_name)sMicro::execute(ExecContext *xc,
        Trace::InstRecord *traceData) const
    {
        Fault fault = NoFault;

        // Getting the source / destination registers
        // We only have one destination reg per micro op, so it's safe to say that the Vd is the first writable reg
        auto &Vd_container = *(RiscvISA::VecRegContainer *)xc->getWritableRegOperand(this, 0);
        RiscvISA::VecRegContainer Vs1_container;
        xc->getRegOperand(this, 0, &Vs1_container);
        RiscvISA::VecRegContainer Vs2_container;
        xc->getRegOperand(this, 1, &Vs2_container);

        //bool has_to_copy_tail_elements = (tail_policy == 0) && (num_non_tail_elements < num_elements_per_reg);
        bool has_to_copy_tail_elements = num_non_tail_elements < num_elements_per_reg;

        auto empty_vmask = std::vector<uint8_t>((num_non_tail_elements + 7)/8, 0xFF);
        uint8_t* vmask = empty_vmask.data();
        // Figure out if we need masks
        if (vmRegID == 0) {
            RiscvISA::VecRegContainer Vmask_container;
            xc->getRegOperand(this, 2, &Vmask_container);
            vmask = Vmask_container.as<uint8_t>();
        }
        uint32_t tail_reg_idx = (vmRegID == 0) ? 3 : 2;
        RiscvISA::VecRegContainer old_Vd_container;
        if (has_to_copy_tail_elements)
            xc->getRegOperand(this, tail_reg_idx, &old_Vd_container);

        bool utilize_mask = vmRegID == 0;

        if (fault == NoFault) {
            if (sew == 8) {
                auto Vd = Vd_container.as<uint8_t>();
                auto Vs2 = Vs2_container.as<uint8_t>();
                auto Vs1 = Vs1_container.as<uint8_t>();
                // process non-tail elements
                for (uint32_t regElemID = 0; regElemID < std::min(num_elements_per_reg, num_non_tail_elements); ++regElemID) {
                    uint32_t maskElemID = mask_offset + regElemID;
                    if (utilize_mask && (bits(vmask[maskElemID / 8], maskElemID % 8, maskElemID % 8) == 0)) {  // "mask undisturbed" policy
                        continue;
                    }
                    %(code)s;
                }
                if (has_to_copy_tail_elements)
                {
                    auto old_Vd = old_Vd_container.as<uint8_t>();
                    for (uint32_t regElemID = num_non_tail_elements; regElemID < num_elements_per_reg; ++regElemID)
                        Vd[regElemID] = old_Vd[regElemID];
                }
            } else if (sew == 16) {
                auto Vd = Vd_container.as<uint16_t>();
                auto Vs2 = Vs2_container.as<uint16_t>();
                auto Vs1 = Vs1_container.as<uint16_t>();
                // process non-tail elements
                for (uint32_t regElemID = 0; regElemID < std::min(num_elements_per_reg, num_non_tail_elements); ++regElemID) {
                    uint32_t maskElemID = mask_offset + regElemID;
                    if (utilize_mask && (bits(vmask[maskElemID / 8], maskElemID % 8, maskElemID % 8) == 0)) {  // "mask undisturbed" policy
                        continue;
                    }
                    %(code)s;
                }
                if (has_to_copy_tail_elements)
                {
                    auto old_Vd = old_Vd_container.as<uint16_t>();
                    for (uint32_t regElemID = num_non_tail_elements; regElemID < num_elements_per_reg; ++regElemID)
                        Vd[regElemID] = old_Vd[regElemID];
                }
            } else if (sew == 32) {
                auto Vd = Vd_container.as<uint32_t>();
                auto Vs2 = Vs2_container.as<uint32_t>();
                auto Vs1 = Vs1_container.as<uint32_t>();
                // process non-tail elements
                for (uint32_t regElemID = 0; regElemID < std::min(num_elements_per_reg, num_non_tail_elements); ++regElemID) {
                    uint32_t maskElemID = mask_offset + regElemID;
                    if (utilize_mask && (bits(vmask[maskElemID / 8], maskElemID % 8, maskElemID % 8) == 0)) { // "mask undisturbed" policy
                        continue;
                    }
                    %(code)s;
                }
                if (has_to_copy_tail_elements)
                {
                    auto old_Vd = old_Vd_container.as<uint32_t>();
                    for (uint32_t regElemID = num_non_tail_elements; regElemID < num_elements_per_reg; ++regElemID)
                        Vd[regElemID] = old_Vd[regElemID];
                }
            } else if (sew == 64) {
                auto Vd = Vd_container.as<uint64_t>();
                auto Vs2 = Vs2_container.as<uint64_t>();
                auto Vs1 = Vs1_container.as<uint64_t>();
                // process non-tail elements
                for (uint32_t regElemID = 0; regElemID < std::min(num_elements_per_reg, num_non_tail_elements); ++regElemID) {
                    uint32_t maskElemID = mask_offset + regElemID;
                    if (utilize_mask && (bits(vmask[maskElemID / 8], maskElemID % 8, maskElemID % 8) == 0)) { // "mask undisturbed" policy
                        continue;
                    }
                    %(code)s;
                }
                if (has_to_copy_tail_elements)
                {
                    auto old_Vd = old_Vd_container.as<uint64_t>();
                    for (uint32_t regElemID = num_non_tail_elements; regElemID < num_elements_per_reg; ++regElemID)
                        Vd[regElemID] = old_Vd[regElemID];
                }
            } else {
                std::string error = csprintf(
                    "Illegal vsewb value in VTYPE: 0x%x\n", sew);
                return std::make_shared<IllegalInstFault>(error, machInst);
            }

            if (fault == NoFault) {
                if (traceData) {
                    traceData->setData(vecRegClass, &Vd_container);
                }
            }
        }

        return fault;
    }
}};

def template VectorVdVs2Vs1MicroDeclare {{
    //
    // Static instruction class for "%(mnemonic)s".
    //
    class %(class_name)s::%(class_name)sMicro : public %(base_class)s
    {
      private:
        // Example:
        // vadd.vv         31..26=0x00 vm vs2 vs1 14..12=0x0 vd 6..0=0x57
        // Sources: up to 8 vector regs starting at Vs2 and
        //          up to 8 vector regs starting at Vs1 and
        //          1 mask register and
        //          up to 1 dest register.
        RegId srcRegIdxArr[1 + 1 + 1 + 1];
        // Destinations: up to 8 vector regs starting at Vd
        RegId destRegIdxArr[1];

      public:
        /// Constructor.
        %(class_name)sMicro(MachInst machInst, RiscvISA::VTYPE machVtype,
        uint32_t machVl, uint64_t vdRegID, uint64_t vs1RegID,
        uint64_t vs2RegID, uint64_t vmRegID, uint64_t mask_offset,
        uint64_t num_elements_per_reg, uint64_t num_non_tail_elements,
        uint64_t sew, uint64_t mask_policy, uint64_t tail_policy);
        Fault execute(ExecContext *, Trace::InstRecord *) const override;
        using %(base_class)s::generateDisassembly;
    };
}};

def format VectorVdVs2Vs1MacroOp(code, *opt_flags) {{
    macro_iop = InstObjParams(name, Name, 'VectorVdVs2Vs1MacroOp', code, opt_flags)
    header_output = VectorMacroDeclare.subst(macro_iop)
    decoder_output = VectorVdVs2Vs1MacroOpConstructor.subst(macro_iop)
    decode_block = VectorMacroDecode.subst(macro_iop)
    exec_output = VectorMacroExecute.subst(macro_iop)


    uop_iop = InstObjParams(name, Name, 'VectorVdVs2Vs1MicroOp', code, opt_flags)
    header_output += VectorVdVs2Vs1MicroDeclare.subst(uop_iop)
    decoder_output += VectorVdVs2Vs1MicroConstructor.subst(uop_iop)
    decode_block += VectorDecode.subst(uop_iop)
    exec_output += VectorVdVs2Vs1OpMicroExecute.subst(uop_iop)
}};

// --- End of VectorVdVs2Vs1

// Start of VectorVRXUNARY0

def template VectorVRXUNARY0Constructor {{
    %(class_name)s::%(class_name)s(MachInst machInst, RiscvISA::VTYPE machVtype, uint32_t machVl, int vlen)
        : %(base_class)s("%(mnemonic)s", machInst, VectorVRXUNARY0OpClass, machVtype, machVl, vlen)
    {
        %(set_reg_idx_arr)s;
        %(constructor)s;
    }
}};

def template VectorVRXUNARY0Execute {{
    Fault
    %(class_name)s::execute(ExecContext *xc,
        Trace::InstRecord *traceData) const
    {
        Fault fault = NoFault;

        VTYPE vtype = xc->readMiscReg(MISCREG_VTYPE);
        size_t sewb = getSew(vtype.vsew) / 8;

        uint64_t Rs1 = xc->getRegOperand(this, 0);
        auto &Vd_container = *(RiscvISA::VecRegContainer *)xc->getWritableRegOperand(this, 0);

        if (fault == NoFault) {
            Rs1 &= mask(sewb * 8);
            if (sewb == 1) {
                auto Vd = Vd_container.as<uint8_t>();
                %(code)s;
            } else if (sewb == 2) {
                auto Vd = Vd_container.as<uint16_t>();
                %(code)s;
            } else if (sewb == 4) {
                auto Vd = Vd_container.as<uint32_t>();
                %(code)s;
            } else if (sewb == 8) {
                auto Vd = Vd_container.as<uint64_t>();
                %(code)s;
            } else {
                std::string error = csprintf(
                    "Illegal vsewb value in VTYPE: 0x%x\n", vtype.vsew);
                fault = std::make_shared<IllegalInstFault>(error, machInst);
            }

            if (fault == NoFault) {
                if (traceData) {
                    traceData->setData(vecRegClass, &Vd_container);
                }
            }
        }
        return fault;
    }
}};

def template VectorVRXUNARY0Declare {{
    //
    // Static instruction class for "%(mnemonic)s".
    //
    class %(class_name)s : public %(base_class)s
    {
      private:
        // Example:
        // vmv.s.x        31..26=0x10 25=1 24..20=0 rs1 14..12=0x6 vd 6..0=0x57
        RegId srcRegIdxArr[1];

        // Rd
        RegId destRegIdxArr[8];

      public:
        /// Constructor.
        %(class_name)s(MachInst machInst, RiscvISA::VTYPE vtype, uint32_t vl, int vlen);
        Fault execute(ExecContext *, Trace::InstRecord *) const override;
        using %(base_class)s::generateDisassembly;
    };
}};

def format VectorVRXUNARY0Op(code, *opt_flags) {{
    iop = InstObjParams(name, Name, 'VectorVRXUNARY0Op', code, opt_flags)
    header_output = VectorVRXUNARY0Declare.subst(iop)
    decoder_output = VectorVRXUNARY0Constructor.subst(iop)
    decode_block = VectorDecode.subst(iop)
    exec_output = VectorVRXUNARY0Execute.subst(iop)
}};

// --- End of VectorVRXUNARY0

// --- Start of VectorSameElementWidthIntegerReductionOpMacro

def template VectorSameElementWidthIntegerReductionMacroConstructor {{
    %(class_name)s::%(class_name)s(MachInst machInst, RiscvISA::VTYPE machVtype, uint32_t machVl, int vlen)
        : %(base_class)s("%(mnemonic)s", machInst, VectorReductionMacroOpClass, machVtype, machVl, vlen)
    {
        // Example:
        // vadd.vv         31..26=0x00 vm vs2 vs1 14..12=0x0 vd 6..0=0x57

        //_numTypedDestRegs[VecRegClass] =
        //    ceil((float) machVl / (VecRegSizeBytes / sewb));
        //assert((VD % alignToPowerOfTwo(_numTypedDestRegs[VecRegClass])) == 0);
        //assert((VS1 % alignToPowerOfTwo(_numTypedDestRegs[VecRegClass])) == 0);
        //assert((VS2 % alignToPowerOfTwo(_numTypedDestRegs[VecRegClass])) == 0);

        auto sew = getSew(machVtype.vsew);
        uint32_t num_elements_per_reg = vlen / sew;
        uint32_t element_count = machVl;

        auto num_regs = vlmulToNumRegs(machVtype.vlmul);
        microops = std::vector<StaticInstPtr>();

        for (uint32_t reg_id_offset = 0; reg_id_offset < num_regs; reg_id_offset++)
        {
            bool use_VS1 = reg_id_offset == 0;
            StaticInstPtr uop = new %(class_name)sMicro(machInst, machVtype, machVl,
                VD, VS1, VS2+reg_id_offset, // Keep VS1 to create the read dependency on VS1
                VM, reg_id_offset*num_elements_per_reg, num_elements_per_reg,
                (element_count < num_elements_per_reg) ? element_count : num_elements_per_reg,
                sew, (uint64_t)machVtype.vma, (uint64_t)machVtype.vta, use_VS1);
            element_count = (element_count >= num_elements_per_reg) ? (element_count - num_elements_per_reg) : 0;
            microops.push_back(std::move(uop));
        }

        microops.front()->setFlag(IsFirstMicroop);
        microops.back()->setFlag(IsLastMicroop);

        flags[IsVector] = true;
    }
}};

def template VectorSameElementWidthIntegerReductionMicroDeclare {{
    //
    // Static instruction class for "%(mnemonic)s".
    //
    class %(class_name)s::%(class_name)sMicro : public %(base_class)s
    {
      private:
        // Example:
        // vadd.vv         31..26=0x00 vm vs2 vs1 14..12=0x0 vd 6..0=0x57
        // Sources: up to 1 vector regs starting at Vs2 and
        //          one scalar in Vs1 and
        //          1 mask register and
        //          1 dest register
        RegId srcRegIdxArr[1 + 1 + 1 + 1];
        // Destinations: One vector containing a scalar
        RegId destRegIdxArr[1];
        bool use_VS1;

      public:
        /// Constructor.
        %(class_name)sMicro(MachInst machInst, RiscvISA::VTYPE machVtype,
        uint32_t machVl, uint64_t vdRegID, uint64_t vs1RegID,
        uint64_t vs2RegID, uint64_t vmRegID, uint64_t mask_offset,
        uint64_t num_elements_per_reg, uint64_t num_non_tail_elements,
        uint64_t sew, uint64_t mask_policy, uint64_t tail_policy,
        bool use_VS1);
        Fault execute(ExecContext *, Trace::InstRecord *) const override;
        using %(base_class)s::generateDisassembly;
    };
}};

def template VectorSameElementWidthIntegerReductionMicroConstructor {{
    %(class_name)s::%(class_name)sMicro::%(class_name)sMicro(MachInst machInst,
        RiscvISA::VTYPE machVtype, uint32_t machVl,
        uint64_t vdRegID, uint64_t vs1RegID, uint64_t vs2RegID,
        uint64_t vmRegID, uint64_t mask_offset,
        uint64_t num_elements_per_reg, uint64_t num_non_tail_elements,
        uint64_t sew, uint64_t mask_policy, uint64_t tail_policy, bool use_VS1)
        : %(base_class)s("%(mnemonic)s", machInst, VectorReductionMicroOpClass,
            vdRegID, vs1RegID, vs2RegID, vmRegID, mask_offset,
            num_elements_per_reg, num_non_tail_elements,
            sew, mask_policy, tail_policy)
    {
        %(set_reg_idx_arr)s;

        // Example:
        // vadd.vv         31..26=0x00 vm vs2 vs1 14..12=0x0 vd 6..0=0x57
        // vreg[vdRegID] = vreg[vs1RegID] + vreg[vs2RegID]

        // Set register dependencies
        setDestRegIdx(_numDestRegs++, vecRegClass[vdRegID]);
        setSrcRegIdx(_numSrcRegs++, vecRegClass[vs1RegID]);
        setSrcRegIdx(_numSrcRegs++, vecRegClass[vs2RegID]);
        if (vmRegID == 0) { // The mask register is always v0
            // Masked instruction.
            setSrcRegIdx(_numSrcRegs++, vecRegClass[0]);
        }
        if (num_non_tail_elements < num_elements_per_reg)
            setSrcRegIdx(_numSrcRegs++, vecRegClass[vdRegID]);

        this->use_VS1 = use_VS1;

        _numVecSrcRegs = _numSrcRegs;

        flags[IsInteger] = true;
        flags[IsVector] = true;
        flags[IsMicroop] = true;
    }
}};

def template VectorSameElementWidthIntegerReductionMicroExecute {{
    Fault
    %(class_name)s::%(class_name)sMicro::execute(ExecContext *xc,
        Trace::InstRecord *traceData) const
    {
        Fault fault = NoFault;

        // Getting the source / destination registers
        // We only have one destination reg per micro op, so it's safe to say that the Vd is the first writable reg
        auto &Vd_container = *(RiscvISA::VecRegContainer *)xc->getWritableRegOperand(this, 0);
        RiscvISA::VecRegContainer Vs1_container;
        xc->getRegOperand(this, 0, &Vs1_container);
        RiscvISA::VecRegContainer Vs2_container;
        xc->getRegOperand(this, 1, &Vs2_container);

        bool has_to_copy_tail_elements = num_non_tail_elements < num_elements_per_reg;

        auto empty_vmask = std::vector<uint8_t>((num_non_tail_elements + 7)/8, 0xFF);
        uint8_t* vmask = empty_vmask.data();
        // Figure out if we need masks
        if (vmRegID == 0) {
            RiscvISA::VecRegContainer Vmask_container;
            xc->getRegOperand(this, 2, &Vmask_container);
            vmask = Vmask_container.as<uint8_t>();
        }

        uint32_t tail_reg_idx = (vmRegID == 0) ? 3 : 2;
        RiscvISA::VecRegContainer old_Vd_container;
        if (has_to_copy_tail_elements)
            xc->getRegOperand(this, tail_reg_idx, &old_Vd_container);

        bool utilize_mask = vmRegID == 0;

        if (fault == NoFault) {
            if (sew == 8) {
                auto Vd = Vd_container.as<uint8_t>();
                auto Vs2 = Vs2_container.as<uint8_t>();
                auto Vs1 = Vs1_container.as<uint8_t>();
                if (this->use_VS1)
                    Vd[0] = Vs1[0];
                // process non-tail elements
                for (uint32_t regElemID = 0; regElemID < std::min(num_elements_per_reg, num_non_tail_elements); ++regElemID) {
                    uint32_t maskElemID = mask_offset + regElemID;
                    if (utilize_mask && (bits(vmask[maskElemID / 8], maskElemID % 8, maskElemID % 8) == 0)) {  // "mask undisturbed" policy
                        continue;
                    }
                    %(code)s;
                }
                if (has_to_copy_tail_elements)
                {
                    auto old_Vd = old_Vd_container.as<uint8_t>();
                    for (uint32_t regElemID = num_non_tail_elements; regElemID < num_elements_per_reg; ++regElemID) {
                        Vd[regElemID] = old_Vd[regElemID];
                    }
                }
            } else if (sew == 16) {
                auto Vd = Vd_container.as<uint16_t>();
                auto Vs2 = Vs2_container.as<uint16_t>();
                auto Vs1 = Vs1_container.as<uint16_t>();
                if (this->use_VS1)
                    Vd[0] = Vs1[0];
                // process non-tail elements
                for (uint32_t regElemID = 0; regElemID < std::min(num_elements_per_reg, num_non_tail_elements); ++regElemID) {
                    uint32_t maskElemID = mask_offset + regElemID;
                    if (utilize_mask && (bits(vmask[maskElemID / 8], maskElemID % 8, maskElemID % 8) == 0)) {  // "mask undisturbed" policy
                        continue;
                    }
                    %(code)s;
                }
                if (has_to_copy_tail_elements)
                {
                    auto old_Vd = old_Vd_container.as<uint16_t>();
                    for (uint32_t regElemID = num_non_tail_elements; regElemID < num_elements_per_reg; ++regElemID) {
                        Vd[regElemID] = old_Vd[regElemID];
                    }
                }
            } else if (sew == 32) {
                auto Vd = Vd_container.as<uint32_t>();
                auto Vs2 = Vs2_container.as<uint32_t>();
                auto Vs1 = Vs1_container.as<uint32_t>();
                if (this->use_VS1)
                    Vd[0] = Vs1[0];
                // process non-tail elements
                for (uint32_t regElemID = 0; regElemID < std::min(num_elements_per_reg, num_non_tail_elements); ++regElemID) {
                    uint32_t maskElemID = mask_offset + regElemID;
                    if (utilize_mask && (bits(vmask[maskElemID / 8], maskElemID % 8, maskElemID % 8) == 0)) { // "mask undisturbed" policy
                        continue;
                    }
                    %(code)s;
                }
                if (has_to_copy_tail_elements)
                {
                    auto old_Vd = old_Vd_container.as<uint32_t>();
                    for (uint32_t regElemID = num_non_tail_elements; regElemID < num_elements_per_reg; ++regElemID) {
                        Vd[regElemID] = old_Vd[regElemID];
                    }
                }
            } else if (sew == 64) {
                auto Vd = Vd_container.as<uint64_t>();
                auto Vs2 = Vs2_container.as<uint64_t>();
                auto Vs1 = Vs1_container.as<uint64_t>();
                if (this->use_VS1)
                    Vd[0] = Vs1[0];
                // process non-tail elements
                for (uint32_t regElemID = 0; regElemID < std::min(num_elements_per_reg, num_non_tail_elements); ++regElemID) {
                    uint32_t maskElemID = mask_offset + regElemID;
                    if (utilize_mask && (bits(vmask[maskElemID / 8], maskElemID % 8, maskElemID % 8) == 0)) { // "mask undisturbed" policy
                        continue;
                    }
                    %(code)s;
                }
                if (has_to_copy_tail_elements)
                {
                    auto old_Vd = old_Vd_container.as<uint64_t>();
                    for (uint32_t regElemID = num_non_tail_elements; regElemID < num_elements_per_reg; ++regElemID) {
                        Vd[regElemID] = old_Vd[regElemID];
                    }
                }
            } else {
                std::string error = csprintf(
                    "Illegal vsewb value in VTYPE: 0x%x\n", sew);
                return std::make_shared<IllegalInstFault>(error, machInst);
            }

            if (fault == NoFault) {
                if (traceData) {
                    traceData->setData(vecRegClass, &Vd_container);
                }
            }
        }

        return fault;
    }
}};

def format VectorSameElementWidthIntegerReductionMacroOp(code, *opt_flags) {{
    macro_iop = InstObjParams(name, Name, 'VectorVdVs2Vs1MacroOp', code, opt_flags)
    header_output = VectorMacroDeclare.subst(macro_iop)
    decoder_output = VectorSameElementWidthIntegerReductionMacroConstructor.subst(macro_iop)
    decode_block = VectorMacroDecode.subst(macro_iop)
    exec_output = VectorMacroExecute.subst(macro_iop)


    uop_iop = InstObjParams(name, Name, 'VectorVdVs2Vs1MicroOp', code, opt_flags)
    header_output += VectorSameElementWidthIntegerReductionMicroDeclare.subst(uop_iop)
    decoder_output += VectorSameElementWidthIntegerReductionMicroConstructor.subst(uop_iop)
    decode_block += VectorMicroDecode.subst(uop_iop)
    exec_output += VectorSameElementWidthIntegerReductionMicroExecute.subst(uop_iop)
}};

// --- End of VectorSameElementWidthIntegerReductionOpMacro

// --- Start of VectorVWXUNARY0

def template VectorVWXUNARY0Constructor {{
    %(class_name)s::%(class_name)s(MachInst machInst, RiscvISA::VTYPE machVtype, uint32_t machVl, int vlen)
        : %(base_class)s("%(mnemonic)s", machInst, VectorVWXUNARY0OpClass, machVtype, machVl, vlen)
    {
        %(set_reg_idx_arr)s;
        %(constructor)s;
    }
}};

def template VectorVWXUNARY0Execute {{
    Fault
    %(class_name)s::execute(ExecContext *xc,
        Trace::InstRecord *traceData) const
    {
        Fault fault = NoFault;

        VTYPE vtype = xc->readMiscReg(MISCREG_VTYPE);
        size_t sewb = getSew(vtype.vsew) / 8;

        uint64_t Rd = 0;
        RiscvISA::VecRegContainer Vs2_container;
        xc->getRegOperand(this, 0, &Vs2_container);

        if (fault == NoFault) {
            if (sewb == 1) {
                auto Vs2 = Vs2_container.as<uint8_t>();
                %(code)s;
                Rd = sext<8>(Rd);
            } else if (sewb == 2) {
                auto Vs2 = Vs2_container.as<uint16_t>();
                %(code)s;
                Rd = sext<16>(Rd);
            } else if (sewb == 4) {
                auto Vs2 = Vs2_container.as<uint32_t>();
                %(code)s;
                Rd = sext<32>(Rd);
            } else if (sewb == 8) {
                auto Vs2 = Vs2_container.as<uint64_t>();
                %(code)s;
                Rd = sext<64>(Rd);
            } else {
                std::string error = csprintf(
                    "Illegal vsewb value in VTYPE: 0x%x\n", vtype.vsew);
                fault = std::make_shared<IllegalInstFault>(error, machInst);
            }

            if (fault == NoFault) {
                %(op_wb)s;
            }
        }
        return fault;
    }
}};

def template VectorVWXUNARY0Declare {{
    //
    // Static instruction class for "%(mnemonic)s".
    //
    class %(class_name)s : public %(base_class)s
    {
      private:
        // Example:
        // vmv.x.s        31..26=0x10 25=1 vs2 19..15=0 14..12=0x2 rd 6..0=0x57
        RegId srcRegIdxArr[8];

        // Rd
        RegId destRegIdxArr[1];

      public:
        /// Constructor.
        %(class_name)s(MachInst machInst, RiscvISA::VTYPE vtype, uint32_t vl, int vlen);
        Fault execute(ExecContext *, Trace::InstRecord *) const override;
        using %(base_class)s::generateDisassembly;
    };
}};

def format VectorVWXUNARY0Op(code, *opt_flags) {{
    iop = InstObjParams(name, Name, 'VectorVWXUNARY0Op', code, opt_flags)
    header_output = VectorVWXUNARY0Declare.subst(iop)
    decoder_output = VectorVWXUNARY0Constructor.subst(iop)
    decode_block = VectorDecode.subst(iop)
    exec_output = VectorVWXUNARY0Execute.subst(iop)
}};

// --- End of VectorVWXUNARY0

// --- Start of VectorVMUNARY0

def template VectorVMUNARY0MacroOpConstructor {{
    %(class_name)s::%(class_name)s(MachInst machInst, RiscvISA::VTYPE machVtype, uint32_t machVl, int vlen)
        : %(base_class)s("%(mnemonic)s", machInst, VectorVMUNARY0MacroOpClass, machVtype, machVl, vlen)
    {
        // Example:
        // vadd.vv         31..26=0x00 vm vs2 vs1 14..12=0x0 vd 6..0=0x57

        //_numTypedDestRegs[VecRegClass] =
        //    ceil((float) machVl / (VecRegSizeBytes / sewb));
        //assert((VD % alignToPowerOfTwo(_numTypedDestRegs[VecRegClass])) == 0);
        //assert((VS1 % alignToPowerOfTwo(_numTypedDestRegs[VecRegClass])) == 0);
        //assert((VS2 % alignToPowerOfTwo(_numTypedDestRegs[VecRegClass])) == 0);

        auto sew = getSew(machVtype.vsew);
        uint32_t num_elements_per_reg = vlen / sew;
        uint32_t element_count = machVl;

        auto num_vregs = vlmulToNumRegs(machVtype.vlmul);
        microops = std::vector<StaticInstPtr>();

        for (uint32_t reg_id_offset = 0; reg_id_offset < num_vregs; reg_id_offset++)
        {
            StaticInstPtr uop = new %(class_name)sMicro(machInst, machVtype, machVl,
                VD+reg_id_offset, VM, reg_id_offset*num_elements_per_reg, num_elements_per_reg,
                (element_count < num_elements_per_reg) ? element_count : num_elements_per_reg,
                sew, (uint64_t)machVtype.vma, (uint64_t)machVtype.vta);
            element_count = (element_count >= num_elements_per_reg) ? (element_count - num_elements_per_reg) : 0;
            microops.push_back(std::move(uop));
        }

        microops.front()->setFlag(IsFirstMicroop);
        microops.back()->setFlag(IsLastMicroop);

        flags[IsVector] = true;
    }
}};

def template VectorVMUNARY0MicroConstructor {{
    %(class_name)s::%(class_name)sMicro::%(class_name)sMicro(MachInst machInst,
        RiscvISA::VTYPE machVtype, uint32_t machVl,
        uint64_t vdRegID, uint64_t vmRegID, uint64_t mask_offset,
        uint64_t num_elements_per_reg, uint64_t num_non_tail_elements,
        uint64_t sew, uint64_t mask_policy, uint64_t tail_policy)
        : %(base_class)s("%(mnemonic)s", machInst, VectorVMUNARY0MicroOpClass,
            vdRegID, vmRegID, mask_offset,
            num_elements_per_reg, num_non_tail_elements,
            sew, mask_policy, tail_policy)
    {
        %(set_reg_idx_arr)s;

        // Example:
        // vid.v v24
        // vreg[vdRegID][i] = elemID for all i

        // Set register dependencies
        setDestRegIdx(_numDestRegs++, vecRegClass[vdRegID]);
        if (vmRegID == 0) { // The mask register is always v0
            // Masked instruction.
            setSrcRegIdx(_numSrcRegs++, vecRegClass[0]);
        }
        //if (tail_policy == 0) // undisturbed
        if (num_non_tail_elements < num_elements_per_reg)
        {
            setSrcRegIdx(_numSrcRegs++, vecRegClass[vdRegID]);
        }

        _numVecSrcRegs = _numSrcRegs;

        flags[IsInteger] = true;
        flags[IsVector] = true;
        flags[IsMicroop] = true;
    }
}};

def template VectorVMUNARY0OpMicroExecute {{
    Fault
    %(class_name)s::%(class_name)sMicro::execute(ExecContext *xc,
        Trace::InstRecord *traceData) const
    {
        Fault fault = NoFault;

        // Getting the source / destination registers
        // We only have one destination reg per micro op, so it's safe to say that the Vd is the first writable reg
        auto &Vd_container = *(RiscvISA::VecRegContainer *)xc->getWritableRegOperand(this, 0);

        //bool has_to_copy_tail_elements = (tail_policy == 0) && (num_non_tail_elements < num_elements_per_reg);
        bool has_to_copy_tail_elements = num_non_tail_elements < num_elements_per_reg;

        auto empty_vmask = std::vector<uint8_t>((num_non_tail_elements + 7)/8, 0xFF);
        uint8_t* vmask = empty_vmask.data();
        // Figure out if we need masks
        if (vmRegID == 0) {
            RiscvISA::VecRegContainer Vmask_container;
            xc->getRegOperand(this, 0, &Vmask_container);
            vmask = Vmask_container.as<uint8_t>();
        }
        uint32_t tail_reg_idx = (vmRegID == 0) ? 1 : 0;
        RiscvISA::VecRegContainer old_Vd_container;
        if (has_to_copy_tail_elements)
            xc->getRegOperand(this, tail_reg_idx, &old_Vd_container);

        bool utilize_mask = vmRegID == 0;

        if (fault == NoFault) {
            if (sew == 8) {
                auto Vd = Vd_container.as<uint8_t>();
                // process non-tail elements
                for (uint32_t regElemID = 0; regElemID < std::min(num_elements_per_reg, num_non_tail_elements); ++regElemID) {
                    uint32_t maskElemID = mask_offset + regElemID;
                    if (utilize_mask && (bits(vmask[maskElemID / 8], maskElemID % 8, maskElemID % 8) == 0)) {  // "mask undisturbed" policy
                        continue;
                    }
                    %(code)s;
                }
                if (has_to_copy_tail_elements)
                {
                    auto old_Vd = old_Vd_container.as<uint8_t>();
                    for (uint32_t regElemID = num_non_tail_elements; regElemID < num_elements_per_reg; ++regElemID)
                        Vd[regElemID] = old_Vd[regElemID];
                }
            } else if (sew == 16) {
                auto Vd = Vd_container.as<uint16_t>();
                // process non-tail elements
                for (uint32_t regElemID = 0; regElemID < std::min(num_elements_per_reg, num_non_tail_elements); ++regElemID) {
                    uint32_t maskElemID = mask_offset + regElemID;
                    if (utilize_mask && (bits(vmask[maskElemID / 8], maskElemID % 8, maskElemID % 8) == 0)) {  // "mask undisturbed" policy
                        continue;
                    }
                    %(code)s;
                }
                if (has_to_copy_tail_elements)
                {
                    auto old_Vd = old_Vd_container.as<uint16_t>();
                    for (uint32_t regElemID = num_non_tail_elements; regElemID < num_elements_per_reg; ++regElemID)
                        Vd[regElemID] = old_Vd[regElemID];
                }
            } else if (sew == 32) {
                auto Vd = Vd_container.as<uint32_t>();
                // process non-tail elements
                for (uint32_t regElemID = 0; regElemID < std::min(num_elements_per_reg, num_non_tail_elements); ++regElemID) {
                    uint32_t maskElemID = mask_offset + regElemID;
                    if (utilize_mask && (bits(vmask[maskElemID / 8], maskElemID % 8, maskElemID % 8) == 0)) { // "mask undisturbed" policy
                        continue;
                    }
                    %(code)s;
                }
                if (has_to_copy_tail_elements)
                {
                    auto old_Vd = old_Vd_container.as<uint32_t>();
                    for (uint32_t regElemID = num_non_tail_elements; regElemID < num_elements_per_reg; ++regElemID)
                        Vd[regElemID] = old_Vd[regElemID];
                }
            } else if (sew == 64) {
                auto Vd = Vd_container.as<uint64_t>();
                // process non-tail elements
                for (uint32_t regElemID = 0; regElemID < std::min(num_elements_per_reg, num_non_tail_elements); ++regElemID) {
                    uint32_t maskElemID = mask_offset + regElemID;
                    if (utilize_mask && (bits(vmask[maskElemID / 8], maskElemID % 8, maskElemID % 8) == 0)) { // "mask undisturbed" policy
                        continue;
                    }
                    %(code)s;
                }
                if (has_to_copy_tail_elements)
                {
                    auto old_Vd = old_Vd_container.as<uint64_t>();
                    for (uint32_t regElemID = num_non_tail_elements; regElemID < num_elements_per_reg; ++regElemID)
                        Vd[regElemID] = old_Vd[regElemID];
                }
            } else {
                std::string error = csprintf(
                    "Illegal vsewb value in VTYPE: 0x%x\n", sew);
                return std::make_shared<IllegalInstFault>(error, machInst);
            }

            if (fault == NoFault) {
                if (traceData) {
                    traceData->setData(vecRegClass, &Vd_container);
                }
            }
        }

        return fault;
    }
}};

def template VectorVMUNARY0MicroDeclare {{
    //
    // Static instruction class for "%(mnemonic)s".
    //
    class %(class_name)s::%(class_name)sMicro : public %(base_class)s
    {
      private:
        // Example:
        // vid.v v24, vm
        // Sources: 1 mask register and
        //          up to 1 dest register.
        RegId srcRegIdxArr[1 + 1];
        // Destinations: 1 dest register.
        RegId destRegIdxArr[1];

      public:
        /// Constructor.
        %(class_name)sMicro(MachInst machInst, RiscvISA::VTYPE machVtype,
        uint32_t machVl, uint64_t vdRegID, uint64_t vmRegID,
        uint64_t mask_offset,
        uint64_t num_elements_per_reg, uint64_t num_non_tail_elements,
        uint64_t sew, uint64_t mask_policy, uint64_t tail_policy);
        Fault execute(ExecContext *, Trace::InstRecord *) const override;
        using %(base_class)s::generateDisassembly;
    };
}};

def format VectorVMUNARY0MacroOp(code, *opt_flags) {{
    macro_iop = InstObjParams(name, Name, 'VectorVMUNARY0MacroOp', code, opt_flags)
    header_output = VectorMacroDeclare.subst(macro_iop)
    decoder_output = VectorVMUNARY0MacroOpConstructor.subst(macro_iop)
    decode_block = VectorMacroDecode.subst(macro_iop)
    exec_output = VectorMacroExecute.subst(macro_iop)


    uop_iop = InstObjParams(name, Name, 'VectorVMUNARY0MicroOp', code, opt_flags)
    header_output += VectorVMUNARY0MicroDeclare.subst(uop_iop)
    decoder_output += VectorVMUNARY0MicroConstructor.subst(uop_iop)
    decode_block += VectorDecode.subst(uop_iop)
    exec_output += VectorVMUNARY0OpMicroExecute.subst(uop_iop)
}};

// --- End of VectorVMUNARY0

// --- Start of VectorWholeRegisterMove

def template VectorWholeRegisterMoveMacroOpConstructor {{
    %(class_name)s::%(class_name)s(MachInst machInst, RiscvISA::VTYPE machVtype, uint32_t machVl, int vlen)
        : %(base_class)s("%(mnemonic)s", machInst, VectorWholeRegisterMoveMacroOpClass)
    {
        // Example:
        // vmv1r v1, v2

        uint32_t nregs = 0;
        %(code)s;

        auto num_vregs = nregs;
        microops = std::vector<StaticInstPtr>();

        for (uint32_t reg_id_offset = 0; reg_id_offset < num_vregs; reg_id_offset++)
        {
            StaticInstPtr uop = new %(class_name)sMicro(machInst, VD+reg_id_offset, VS2+reg_id_offset);
            microops.push_back(std::move(uop));
        }

        microops.front()->setFlag(IsFirstMicroop);
        microops.back()->setFlag(IsLastMicroop);

        flags[IsVector] = true;
    }
}};

def template VectorWholeRegisterMoveMicroConstructor {{
    %(class_name)s::%(class_name)sMicro::%(class_name)sMicro(MachInst machInst,
        uint64_t vdRegID, uint64_t vs2RegID)
        : %(base_class)s("%(mnemonic)s", machInst, VectorWholeRegisterMoveMicroOpClass,
            vdRegID, vs2RegID)
    {
        %(set_reg_idx_arr)s;

        // Example:
        // vmv1r v1, v2
        // vd[elemID] = vs2[elemID] for all i

        // Set register dependencies
        setDestRegIdx(_numDestRegs++, vecRegClass[vdRegID]);
        setSrcRegIdx(_numSrcRegs++, vecRegClass[vs2RegID]);

        _numVecSrcRegs = _numSrcRegs;

        flags[IsInteger] = true;
        flags[IsVector] = true;
        flags[IsMicroop] = true;
    }
}};

def template VectorWholeRegisterMoveOpMicroExecute {{
    Fault
    %(class_name)s::%(class_name)sMicro::execute(ExecContext *xc,
        Trace::InstRecord *traceData) const
    {
        Fault fault = NoFault;

        // Getting the source / destination registers
        // We only have one destination reg per micro op, so it's safe to say that the Vd is the first writable reg
        auto &Vd_container = *(RiscvISA::VecRegContainer *)xc->getWritableRegOperand(this, 0);

        RiscvISA::VecRegContainer Vs2_container;
        xc->getRegOperand(this, 0, &Vs2_container);

        Vd_container = Vs2_container;

        if (fault == NoFault) {
            if (traceData) {
                traceData->setData(vecRegClass, &Vd_container);
            }
        }

        return fault;
    }
}};

def template VectorWholeRegisterMoveMicroDeclare {{
    //
    // Static instruction class for "%(mnemonic)s".
    //
    class %(class_name)s::%(class_name)sMicro : public %(base_class)s
    {
      private:
        // Example:
        // vmv1r v1, v2
        // Source: exactly 1 source register.
        RegId srcRegIdxArr[1];
        // Destination: exactly 1 destination register.
        RegId destRegIdxArr[1];

      public:
        /// Constructor.
        %(class_name)sMicro(MachInst machInst, uint64_t vdRegID, uint64_t vs2RegID);
        Fault execute(ExecContext *, Trace::InstRecord *) const override;
        using %(base_class)s::generateDisassembly;
    };
}};

def format VectorWholeRegisterMoveMacroOp(code, *opt_flags) {{
    macro_iop = InstObjParams(name, Name, 'VectorWholeRegisterMoveMacroOp', code, opt_flags)
    header_output = VectorMacroDeclare.subst(macro_iop)
    decoder_output = VectorWholeRegisterMoveMacroOpConstructor.subst(macro_iop)
    decode_block = VectorMacroDecode.subst(macro_iop)
    exec_output = VectorMacroExecute.subst(macro_iop)


    uop_iop = InstObjParams(name, Name, 'VectorWholeRegisterMoveMicroOp', code, opt_flags)
    header_output += VectorWholeRegisterMoveMicroDeclare.subst(uop_iop)
    decoder_output += VectorWholeRegisterMoveMicroConstructor.subst(uop_iop)
    decode_block += VectorDecode.subst(uop_iop)
    exec_output += VectorWholeRegisterMoveOpMicroExecute.subst(uop_iop)
}};

// --- End of VectorWholeRegisterMove

// --- Start of VectorVdVs2Rs1

def template VectorVdVs2Rs1MacroOpConstructor {{
    %(class_name)s::%(class_name)s(MachInst machInst, RiscvISA::VTYPE machVtype, uint32_t machVl, int vlen)
        : %(base_class)s("%(mnemonic)s", machInst, VectorVdVs2Vs1MacroOpClass, machVtype, machVl, vlen)
    {
        // Example:
        // vadd.vx

        auto sew = getSew(machVtype.vsew);
        uint32_t num_elements_per_reg = vlen / sew;
        uint32_t element_count = machVl;

        auto num_vregs = vlmulToNumRegs(machVtype.vlmul);
        microops = std::vector<StaticInstPtr>();

        for (uint32_t reg_id_offset = 0; reg_id_offset < num_vregs; reg_id_offset++)
        {
            StaticInstPtr uop = new %(class_name)sMicro(machInst, machVtype, machVl,
                VD+reg_id_offset, RS1, VS2+reg_id_offset,
                VM, reg_id_offset*num_elements_per_reg, num_elements_per_reg,
                (element_count < num_elements_per_reg) ? element_count : num_elements_per_reg,
                sew, (uint64_t)machVtype.vma, (uint64_t)machVtype.vta);
            element_count = (element_count >= num_elements_per_reg) ? (element_count - num_elements_per_reg) : 0;
            microops.push_back(std::move(uop));
        }

        microops.front()->setFlag(IsFirstMicroop);
        microops.back()->setFlag(IsLastMicroop);

        flags[IsVector] = true;
    }
}};

def template VectorVdVs2Rs1MicroConstructor {{
    %(class_name)s::%(class_name)sMicro::%(class_name)sMicro(MachInst machInst,
        RiscvISA::VTYPE machVtype, uint32_t machVl,
        uint64_t vdRegID, uint64_t rs1RegID, uint64_t vs2RegID,
        uint64_t vmRegID, uint64_t mask_offset,
        uint64_t num_elements_per_reg, uint64_t num_non_tail_elements,
        uint64_t sew, uint64_t mask_policy, uint64_t tail_policy)
        : %(base_class)s("%(mnemonic)s", machInst, VectorVdVs2Rs1MicroOpClass,
            vdRegID, rs1RegID, vs2RegID, vmRegID, mask_offset,
            num_elements_per_reg, num_non_tail_elements,
            sew, mask_policy, tail_policy)
    {
        %(set_reg_idx_arr)s;

        // Example:
        // vadd.vx
        // vreg[vdRegID] = reg[rs1RegID] + vreg[vs2RegID]

        // Set register dependencies
        setDestRegIdx(_numDestRegs++, vecRegClass[vdRegID]);
        setSrcRegIdx(_numSrcRegs++, intRegClass[rs1RegID]);
        setSrcRegIdx(_numSrcRegs++, vecRegClass[vs2RegID]);
        if (vmRegID == 0) { // The mask register is always v0
            // Masked instruction.
            setSrcRegIdx(_numSrcRegs++, vecRegClass[0]);
        }
        //if (tail_policy == 0) // undisturbed
        if (num_non_tail_elements < num_elements_per_reg)
        {
            //setSrcRegIdx(_numSrcRegs++, RegId(VecRegClass, vdRegID));
            setSrcRegIdx(_numSrcRegs++, vecRegClass[vdRegID]);
        }

        _numVecSrcRegs = _numSrcRegs - 1;

        flags[IsInteger] = true;
        flags[IsVector] = true;
        flags[IsMicroop] = true;
    }
}};

def template VectorVdVs2Rs1OpMicroExecute {{
    Fault
    %(class_name)s::%(class_name)sMicro::execute(ExecContext *xc,
        Trace::InstRecord *traceData) const
    {
        Fault fault = NoFault;

        // Getting the source / destination registers
        // We only have one destination reg per micro op, so it's safe to say that the Vd is the first writable reg
        auto &Vd_container = *(RiscvISA::VecRegContainer *)xc->getWritableRegOperand(this, 0);
        uint64_t Rs1 = xc->getRegOperand(this, 0);
        RiscvISA::VecRegContainer Vs2_container;
        xc->getRegOperand(this, 1, &Vs2_container);

        //bool has_to_copy_tail_elements = (tail_policy == 0) && (num_non_tail_elements < num_elements_per_reg);
        bool has_to_copy_tail_elements = num_non_tail_elements < num_elements_per_reg;

        auto empty_vmask = std::vector<uint8_t>((num_non_tail_elements + 7)/8, 0xFF);
        uint8_t* vmask = empty_vmask.data();
        // Figure out if we need masks
        if (vmRegID == 0) {
            RiscvISA::VecRegContainer Vmask_container;
            xc->getRegOperand(this, 2, &Vmask_container);
            vmask = Vmask_container.as<uint8_t>();
        }
        uint32_t tail_reg_idx = (vmRegID == 0) ? 3 : 2;
        RiscvISA::VecRegContainer old_Vd_container;
        if (has_to_copy_tail_elements)
            xc->getRegOperand(this, tail_reg_idx, &old_Vd_container);

        bool utilize_mask = vmRegID == 0;

        if (fault == NoFault) {
            if (sew == 8) {
                auto Vd = Vd_container.as<uint8_t>();
                auto Vs2 = Vs2_container.as<uint8_t>();
                // process non-tail elements
                for (uint32_t regElemID = 0; regElemID < std::min(num_elements_per_reg, num_non_tail_elements); ++regElemID) {
                    uint32_t maskElemID = mask_offset + regElemID;
                    if (utilize_mask && (bits(vmask[maskElemID / 8], maskElemID % 8, maskElemID % 8) == 0)) {  // "mask undisturbed" policy
                        continue;
                    }
                    %(code)s;
                }
                if (has_to_copy_tail_elements)
                {
                    auto old_Vd = old_Vd_container.as<uint8_t>();
                    for (uint32_t regElemID = num_non_tail_elements; regElemID < num_elements_per_reg; ++regElemID)
                        Vd[regElemID] = old_Vd[regElemID];
                }
            } else if (sew == 16) {
                auto Vd = Vd_container.as<uint16_t>();
                auto Vs2 = Vs2_container.as<uint16_t>();
                // process non-tail elements
                for (uint32_t regElemID = 0; regElemID < std::min(num_elements_per_reg, num_non_tail_elements); ++regElemID) {
                    uint32_t maskElemID = mask_offset + regElemID;
                    if (utilize_mask && (bits(vmask[maskElemID / 8], maskElemID % 8, maskElemID % 8) == 0)) {  // "mask undisturbed" policy
                        continue;
                    }
                    %(code)s;
                }
                if (has_to_copy_tail_elements)
                {
                    auto old_Vd = old_Vd_container.as<uint16_t>();
                    for (uint32_t regElemID = num_non_tail_elements; regElemID < num_elements_per_reg; ++regElemID)
                        Vd[regElemID] = old_Vd[regElemID];
                }
            } else if (sew == 32) {
                auto Vd = Vd_container.as<uint32_t>();
                auto Vs2 = Vs2_container.as<uint32_t>();
                // process non-tail elements
                for (uint32_t regElemID = 0; regElemID < std::min(num_elements_per_reg, num_non_tail_elements); ++regElemID) {
                    uint32_t maskElemID = mask_offset + regElemID;
                    if (utilize_mask && (bits(vmask[maskElemID / 8], maskElemID % 8, maskElemID % 8) == 0)) { // "mask undisturbed" policy
                        continue;
                    }
                    %(code)s;
                }
                if (has_to_copy_tail_elements)
                {
                    auto old_Vd = old_Vd_container.as<uint32_t>();
                    for (uint32_t regElemID = num_non_tail_elements; regElemID < num_elements_per_reg; ++regElemID)
                        Vd[regElemID] = old_Vd[regElemID];
                }
            } else if (sew == 64) {
                auto Vd = Vd_container.as<uint64_t>();
                auto Vs2 = Vs2_container.as<uint64_t>();
                // process non-tail elements
                for (uint32_t regElemID = 0; regElemID < std::min(num_elements_per_reg, num_non_tail_elements); ++regElemID) {
                    uint32_t maskElemID = mask_offset + regElemID;
                    if (utilize_mask && (bits(vmask[maskElemID / 8], maskElemID % 8, maskElemID % 8) == 0)) { // "mask undisturbed" policy
                        continue;
                    }
                    %(code)s;
                }
                if (has_to_copy_tail_elements)
                {
                    auto old_Vd = old_Vd_container.as<uint64_t>();
                    for (uint32_t regElemID = num_non_tail_elements; regElemID < num_elements_per_reg; ++regElemID)
                        Vd[regElemID] = old_Vd[regElemID];
                }
            } else {
                std::string error = csprintf(
                    "Illegal vsewb value in VTYPE: 0x%x\n", sew);
                return std::make_shared<IllegalInstFault>(error, machInst);
            }

            if (fault == NoFault) {
                if (traceData) {
                    traceData->setData(vecRegClass, &Vd_container);
                }
            }
        }

        return fault;
    }
}};

def template VectorVdVs2Rs1MicroDeclare {{
    //
    // Static instruction class for "%(mnemonic)s".
    //
    class %(class_name)s::%(class_name)sMicro : public %(base_class)s
    {
      private:
        // Example:
        // vadd.vx vd, vs2, rs1, vm
        RegId srcRegIdxArr[1 + 1 + 1 + 1];
        // Destinations: up to 8 vector regs starting at Vd
        RegId destRegIdxArr[1];

      public:
        /// Constructor.
        %(class_name)sMicro(MachInst machInst, RiscvISA::VTYPE machVtype,
        uint32_t machVl, uint64_t vdRegID, uint64_t rs1RegID,
        uint64_t vs2RegID, uint64_t vmRegID, uint64_t mask_offset,
        uint64_t num_elements_per_reg, uint64_t num_non_tail_elements,
        uint64_t sew, uint64_t mask_policy, uint64_t tail_policy);
        Fault execute(ExecContext *, Trace::InstRecord *) const override;
        using %(base_class)s::generateDisassembly;
    };
}};

def format VectorVdVs2Rs1MacroOp(code, *opt_flags) {{
    macro_iop = InstObjParams(name, Name, 'VectorVdVs2Rs1MacroOp', code, opt_flags)
    header_output = VectorMacroDeclare.subst(macro_iop)
    decoder_output = VectorVdVs2Rs1MacroOpConstructor.subst(macro_iop)
    decode_block = VectorMacroDecode.subst(macro_iop)
    exec_output = VectorMacroExecute.subst(macro_iop)


    uop_iop = InstObjParams(name, Name, 'VectorVdVs2Rs1MicroOp', code, opt_flags)
    header_output += VectorVdVs2Rs1MicroDeclare.subst(uop_iop)
    decoder_output += VectorVdVs2Rs1MicroConstructor.subst(uop_iop)
    decode_block += VectorDecode.subst(uop_iop)
    exec_output += VectorVdVs2Rs1OpMicroExecute.subst(uop_iop)
}};

// --- End of VectorVdVs2Rs1

// --- Start of VectorUnitStrideMemLoad

def template VectorUnitStrideMemLoadStoreMacroConstructor {{
    %(class_name)s::%(class_name)s(MachInst machInst, RiscvISA::VTYPE machVtype, uint32_t machVl, int vlen)
        : %(base_class)s("%(mnemonic)s", machInst, VectorUnitStrideMemLoadMacroOpClass, machVtype, machVl, vlen)
    {
        uint32_t eew = 0;
        switch (FUNCT3) {
            case 0:
                eew = 8;
                break;
            case 5:
                eew = 16;
                break;
            case 6:
                eew = 32;
                break;
            case 7:
                eew = 64;
                break;
            default:
                eew = 0;
        }

        //if (LUMOP == 0 || LUMOP == 0x10) {
        //    // vle32.v        nf 28=0 27..26=0 vm 24..20=0 rs1 14..12=0x6  vd 6..0=0x07
        //    // vle32ff.v        nf 28=0 27..26=0 vm 24..20=0x10 rs1 14..12=0x6  vd 6..0=0x07
        //    _numTypedDestRegs[VecRegClass] = ceil((float) machVl / (VecRegSizeBytes/eewb));
        //} else if (LUMOP == 0x8) {
        //    // vl1re16.v      31..29=0 28=0 27..26=0 25=1 24..20=0x08 rs1 14..12=0x5 vd  6..0=0x07
        //    // vl2re16.v      31..29=1 28=0 27..26=0 25=1 24..20=0x08 rs1 14..12=0x5 vd  6..0=0x07
        //    // vl4re16.v      31..29=3 28=0 27..26=0 25=1 24..20=0x08 rs1 14..12=0x5 vd  6..0=0x07
        //    // vl8re16.v      31..29=7 28=0 27..26=0 25=1 24..20=0x08 rs1 14..12=0x5 vd  6..0=0x07
        //    _numTypedDestRegs[VecRegClass] = NF + 1;
        //} else {
        //    printf("ERROR: Unknown LUMOP value 0x%x for load\n", LUMOP);
        //}
        //assert(NF != 0); // instruction with NFIELDS > 0 is currently not supported

        //assert((VD % alignToPowerOfTwo(_numTypedDestRegs[VecRegClass])) == 0);

        // for (int i = 0; i < _numTypedDestRegs[VecRegClass]; ++i) {
        //     setDestRegIdx(_numDestRegs++, RegId(VecRegClass, VD + i));
        // }

        auto sew = getSew(machVtype.vsew);
        uint32_t num_elements_per_reg = vlen / eew;
        uint32_t element_count = machVl;

        auto num_vregs = eew / sew * vlmulToNumRegs(machVtype.vlmul); // i.e. EMUL
        assert(num_vregs <= 8);

        for (uint32_t reg_id_offset = 0; reg_id_offset < num_vregs; reg_id_offset++)
        {
            for (uint32_t element_index = 0; element_index < num_elements_per_reg; element_index++) // element_index is the index of an element within its vector register
            {
                bool is_tail_element = reg_id_offset*num_elements_per_reg+element_index >= element_count;
                if (!is_tail_element)
                {
                    StaticInstPtr uop = new %(class_name)sMicro(machInst, machVtype, machVl,
                        VD+reg_id_offset, VM, reg_id_offset*num_elements_per_reg+element_index, num_elements_per_reg,
                        (element_count < num_elements_per_reg) ? element_count : num_elements_per_reg,
                        eew, (uint64_t)machVtype.vma, (uint64_t)machVtype.vta);
                    microops.push_back(std::move(uop));
                }
            }
            element_count = (element_count >= num_elements_per_reg) ? (element_count - num_elements_per_reg) : 0; // TODO: refactor this
        }

        if (microops.size() == 0)
        {
            StaticInstPtr uop = new MicroNop();
            microops.push_back(uop);
        }

        microops.front()->setFlag(IsFirstMicroop);
        microops.back()->setFlag(IsLastMicroop);

        flags[IsVector] = true;
    }
}};

def template VectorUnitStrideMemLoadMicroDeclare {{
    //
    // Static instruction class for "%(mnemonic)s".
    //
    class %(class_name)s::%(class_name)sMicro : public %(base_class)s
    {
      private:
        // Example:
        // vle32.v        nf 28=0 27..26=0 vm 24..20=0 rs1 14..12=0x6  vd 6..0=0x07
        // Sources: Rs1 + 1 mask register.
        RegId srcRegIdxArr[1 + 1];
        // Destinations: write to one element in one Vd
        RegId destRegIdxArr[1];

      public:
        /// Constructor.
        %(class_name)sMicro(MachInst machInst, RiscvISA::VTYPE vtype, uint32_t vl,
            uint64_t vdRegID, uint64_t vmRegID, uint64_t mask_offset,
            uint64_t num_elements_per_reg, uint64_t num_non_tail_elements,
            uint64_t eew, uint64_t mask_policy, uint64_t tail_policy);
        Fault execute(ExecContext *, Trace::InstRecord *) const override;
        Fault initiateAcc(ExecContext *, Trace::InstRecord *) const override;
        Fault completeAcc(Packet *, ExecContext *, Trace::InstRecord *) const override;
        using %(base_class)s::generateDisassembly;
    };
}};

def template VectorUnitStrideMemLoadMicroConstructor {{
    %(class_name)s::%(class_name)sMicro::%(class_name)sMicro(MachInst machInst,
        RiscvISA::VTYPE machVtype, uint32_t machVl,
        uint64_t vdRegID, uint64_t vmRegID, uint64_t mask_offset,
        uint64_t num_elements_per_reg, uint64_t num_non_tail_elements,
        uint64_t eew, uint64_t mask_policy, uint64_t tail_policy)
        : %(base_class)s("%(mnemonic)s", machInst, VectorUnitStrideMemLoadMicroOpClass,
            vdRegID, vmRegID, mask_offset,
            num_elements_per_reg, num_non_tail_elements,
            eew, mask_policy, tail_policy)
    {
        %(set_reg_idx_arr)s;

        // Example:
        // vle32.v        nf 28=0 27..26=0 vm 24..20=0 rs1 14..12=0x6  vd 6..0=0x07
        // vreg[vdRegID] = mem[EA+element_index*element_size_bytes]

        //setSrcRegIdx(_numSrcRegs++, RegId(IntRegClass, RS1));
        setSrcRegIdx(_numSrcRegs++, intRegClass[RS1]);

        // Set register dependencies
        //setDestRegIdx(_numDestRegs++, RegId(VecRegClass, vdRegID));
        setDestRegIdx(_numDestRegs++, vecRegClass[vdRegID]);
        if (vmRegID == 0) { // The mask register is always v0
            // Masked instruction.
            //setSrcRegIdx(_numSrcRegs++, RegId(VecRegClass, 0));
            setSrcRegIdx(_numSrcRegs++, vecRegClass[0]);
        }

        _numVecSrcRegs = _numSrcRegs;

        if (mask_offset % num_elements_per_reg == 0 && num_non_tail_elements != 0)
        {
            // pining the destination like SveGatherLoadVIMicroop
            auto dest_reg = destRegIdx(0);
            dest_reg.setNumPinnedWrites(num_non_tail_elements - 1);
            setDestRegIdx(0, dest_reg);
        }

        flags[IsInteger] = true;
        flags[IsLoad] = true;
        flags[IsVector] = true;
        flags[IsMicroop] = true;
    }
}};

def template VectorUnitStrideMemLoadMicroExecute {{
    Fault
    %(class_name)s::%(class_name)sMicro::execute(ExecContext *xc,
        Trace::InstRecord *traceData) const
    {
        Fault fault = NoFault;

        // Getting the source / destination registers
        // We only have one destination reg per micro op, so it's safe to say that the Vd is the first writable reg
        auto &Vd_container = *(RiscvISA::VecRegContainer *)xc->getWritableRegOperand(this, 0);

        bool masked_off = false; // masked_off == true -> do not compute the element; otherwise compute the element if it is not a tail element

        // Figure out if we need masks
        if (vmRegID == 0) {
            RiscvISA::VecRegContainer Vmask_container;
            xc->getRegOperand(this, 1, &Vmask_container);
            auto vmask = Vmask_container.as<uint8_t>();
            masked_off = (bits(vmask[mask_offset / 8], mask_offset % 8, mask_offset % 8) == 0);
        }

        bool utilize_mask = vmRegID == 0;
        uint32_t regElemID = mask_offset % num_elements_per_reg;
        bool is_tail_element = regElemID >= num_non_tail_elements;

        %(op_decl)s;
        Rs1 = xc->getRegOperand(this, 0);

        if (fault == NoFault && (!utilize_mask || !masked_off)) {
            if (eew == 8) {
                if (!is_tail_element)
                {
                    auto Vd = Vd_container.as<uint8_t>();
                    // process non-tail elements
                    Addr offset = mask_offset * sizeof(uint8_t);
                    %(code)s;
                }
                // TODO: apply tail policy to tail elements
            } else if (eew == 16) {
                if (!is_tail_element)
                {
                    auto Vd = Vd_container.as<uint16_t>();
                    // process non-tail elements
                    Addr offset = mask_offset * sizeof(uint16_t);
                    %(code)s;
                }
                // TODO: apply tail policy to tail elements
            } else if (eew == 32) {
                if (!is_tail_element)
                {
                    auto Vd = Vd_container.as<uint32_t>();
                    // process non-tail elements
                    Addr offset = mask_offset * sizeof(uint32_t);
                    %(code)s;
                }
                // TODO: apply tail policy to tail elements
            } else if (eew == 64) {
                if (!is_tail_element)
                {
                    auto Vd = Vd_container.as<uint64_t>();
                    // process non-tail elements
                    Addr offset = mask_offset * sizeof(uint64_t);
                    %(code)s;
                }
                // TODO: apply tail policy to tail elements
            } else {
                //std::string error = csprintf(
                //    "Illegal vsewb value in VTYPE: 0x%x\n", eew);
                //return std::make_shared<IllegalInstFault>(error, machInst);
            }

            if (fault == NoFault) {
                if (traceData) {
                    traceData->setData(vecRegClass, &Vd_container);
                }
            }
        }

        return fault;
    }
}};

def template VectorUnitStrideMemLoadMicroInitiateAcc {{
    Fault
    %(class_name)s::%(class_name)sMicro::initiateAcc(ExecContext *xc,
        Trace::InstRecord *traceData) const
    {
        Fault fault = NoFault;

        Addr EA = 0;
        uint64_t Rs1 = 0;
        Rs1 = xc->getRegOperand(this, 0);
        
        // Getting the source / destination registers
        bool masked_off = false; // masked_off == true -> do not compute the element; otherwise compute the element if it is not a tail element

        // Figure out if we need masks
        if (vmRegID == 0) {
            RiscvISA::VecRegContainer Vmask_container;
            xc->getRegOperand(this, 1, &Vmask_container);
            auto vmask = Vmask_container.as<uint8_t>();
            masked_off = (bits(vmask[mask_offset / 8], mask_offset % 8, mask_offset % 8) == 0);
        }

        bool utilize_mask = vmRegID == 0;
        uint32_t regElemID = mask_offset % num_elements_per_reg;
        bool is_tail_element = regElemID >= num_non_tail_elements;

        if (fault == NoFault && (!utilize_mask || !masked_off)) {
            if (eew == 8) {
                if (!is_tail_element)
                {
                    // process non-tail elements
                    Addr offset = mask_offset * sizeof(uint8_t);
                    EA = Rs1 + offset;
                    uint8_t Mem = {}; // the type of this variable is used for determining how many bytes this mem access returns
                    return initiateMemRead(xc, traceData, EA, Mem, memAccessFlags);
                }
                // TODO: apply tail policy to tail elements
            } else if (eew == 16) {
                if (!is_tail_element)
                {
                    // process non-tail elements
                    Addr offset = mask_offset * sizeof(uint16_t);
                    EA = Rs1 + offset;
                    uint16_t Mem = {}; // the type of this variable is used for determining how many bytes this mem access returns
                    return initiateMemRead(xc, traceData, EA, Mem, memAccessFlags);
                }
                // TODO: apply tail policy to tail elements
            } else if (eew == 32) {
                if (!is_tail_element)
                {
                    // process non-tail elements
                    Addr offset = mask_offset * sizeof(uint32_t);
                    EA = Rs1 + offset;
                    uint32_t Mem = {}; // the type of this variable is used for determining how many bytes this mem access returns
                    return initiateMemRead(xc, traceData, EA, Mem, memAccessFlags);
                }
                // TODO: apply tail policy to tail elements
            } else if (eew == 64) {
                if (!is_tail_element)
                {
                    // process non-tail elements
                    Addr offset = mask_offset * sizeof(uint64_t);
                    EA = Rs1 + offset;
                    uint64_t Mem = {}; // the type of this variable is used for determining how many bytes this mem access returns
                    return initiateMemRead(xc, traceData, EA, Mem, memAccessFlags);
                }
                // TODO: apply tail policy to tail elements
            } else {
                std::string error = csprintf("Illegal value for eew: 0x%x\n", eew);
                return std::make_shared<IllegalInstFault>(error, machInst);
            }
        }
        return NoFault;
    }
}};

def template VectorUnitStrideMemLoadMicroCompleteAcc {{
    Fault
    %(class_name)s::%(class_name)sMicro::completeAcc(Packet *pkt,
        ExecContext *xc, Trace::InstRecord *traceData) const
    {
        Fault fault = NoFault;

        uint32_t regElemID = mask_offset % num_elements_per_reg;
        auto &Vd_container = *(RiscvISA::VecRegContainer *)xc->getWritableRegOperand(this, 0);

        if (eew == 8) {
            uint8_t Mem = {};
            getMemLE(pkt, Mem, traceData);
            auto Vd = Vd_container.as<uint8_t>();
            Vd[regElemID] = Mem;
        } else if (eew == 16) {
            uint16_t Mem = {};
            getMemLE(pkt, Mem, traceData);
            auto Vd = Vd_container.as<uint16_t>();
            Vd[regElemID] = Mem;
        } else if (eew == 32) {
            uint32_t Mem = {};
            getMemLE(pkt, Mem, traceData);
            auto Vd = Vd_container.as<uint32_t>();
            Vd[regElemID] = Mem;
        } else if (eew == 64) {
            uint64_t Mem = {};
            getMemLE(pkt, Mem, traceData);
            auto Vd = Vd_container.as<uint64_t>();
            Vd[regElemID] = Mem;
        }
        return fault;
    }
}};

def format VectorUnitStrideMemLoadMacroOp(code, *opt_flags) {{
    macro_iop = InstObjParams(name, Name, 'VectorUnitStrideMemLoadMacroOp', code, opt_flags)
    header_output = VectorMacroDeclare.subst(macro_iop)
    decoder_output = VectorUnitStrideMemLoadStoreMacroConstructor.subst(macro_iop)
    decode_block = VectorMacroDecode.subst(macro_iop)
    exec_output = VectorMacroExecute.subst(macro_iop)

    uop_iop = InstObjParams(name, Name, 'VectorUnitStrideMemLoadMicroOp', code, opt_flags)
    header_output += VectorUnitStrideMemLoadMicroDeclare.subst(uop_iop)
    decoder_output += VectorUnitStrideMemLoadMicroConstructor.subst(uop_iop)
    decode_block += VectorDecode.subst(uop_iop)
    exec_output += VectorUnitStrideMemLoadMicroExecute.subst(uop_iop)
    exec_output += VectorUnitStrideMemLoadMicroInitiateAcc.subst(uop_iop)
    exec_output += VectorUnitStrideMemLoadMicroCompleteAcc.subst(uop_iop)
}};

// --- End of VectorUnitStrideMemLoad

// Others
def template VectorDecode {{
    return new %(class_name)s(machInst, machVtype, machVl, vlen);
}};

def template VectorMicroDecode {{
    return new %(class_name)s(machInst, machVtype, machVl, vlen);
}};


def template VectorDeclare {{
    //
    // Static instruction class for "%(mnemonic)s".
    //
    class %(class_name)s : public %(base_class)s
    {
      private:
        %(reg_idx_arr_decl)s;

      public:
        /// Constructor.
        %(class_name)s(MachInst machInst, RiscvISA::VTYPE vtype, uint32_t vl, int vlen);
        Fault execute(ExecContext *, Trace::InstRecord *) const override;
        using %(base_class)s::generateDisassembly;
    };
}};

def template VectorMacroDecode {{
    return new %(class_name)s(machInst, machVtype, machVl, vlen);
}};

def template VectorMacroDeclare {{
    //
    // Static instruction class for "%(mnemonic)s".
    //
    class %(class_name)s : public %(base_class)s
    {
      public:
        /// Constructor.
        %(class_name)s(MachInst machInst, RiscvISA::VTYPE vtype, uint32_t vl, int vlen);
        Fault execute(ExecContext *, Trace::InstRecord *) const override;
        using %(base_class)s::generateDisassembly;

      protected:
        class %(class_name)sMicro;
    };
}};

def template VectorMacroExecute {{
    Fault
    %(class_name)s::execute(ExecContext *xc,
        Trace::InstRecord *traceData) const
    {
        std::string error = csprintf("Executing Macro Inst\n");
        return std::make_shared<IllegalInstFault>(error, machInst);
    }
}};

def template VectorCfgDeclare {{
    class %(class_name)s : public %(base_class)s
    {
      private:
        %(reg_idx_arr_decl)s;

      public:
        /// Constructor.
        %(class_name)s(MachInst machInst, RiscvISA::VTYPE vtype, uint32_t vl, int vlen);
        Fault execute(ExecContext *, Trace::InstRecord *) const override;
        using %(base_class)s::generateDisassembly;
    };
}};